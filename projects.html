<html>
<head>
   <title>CoVIS -- Projects</title>
   <META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=ISO-8859-1">
   <META name="author" content="Xiaohui Yuan">
   <META name="keywords" content="Image Processing, Image Fusion, Information Fusion, Data Fusion, 
Artificial Intelligence, Computer Vision and Pattern Recognition, Machine Learning, Data Mining, Association Rule">
<style type="text/css">
h3 {
  color: #008800; 
  text-shadow: black 0.1em 0.1em 0.15em, 1px 1px #333, -1px -1px white;
  letter-spacing: 0.15em; 
  padding: 0.1em; 
  margin: 1em 0.1em
}
a:link {color:#006600; text-decoration:none}
a:visited {color:#006600; text-decoration:none}
a:hover {color:#009900; text-decoration:none}
body {margin:0;}

.navbar {
  position: fixed;
  bottom: 0;
  width: 100%;
  color: white;
  background-color: #003300;
  overflow: auto;
  margin:0 auto; /* centers modern browsers */
  text-align:center; /* centers IE6/7 */
  padding: 15px 20px;
}

.navbar a {
  color: white;
  font: bold 15px/18px Arial;
  padding: 15px 20px;
}

.navbar ul {
  list-style-type: none;
  margin: 0;
  padding: 0;
  overflow: hidden;
  background-color: #003300;
  position: fixed;
  bottom: 0;
  width: 100%;
}

.navbar li {
  float: left;
  font-size: 17
}

.navbar a {
  color: white;
}

.navbar a:hover {
  background-color: #001100;
}

.navbar-left {
  float: left;
  position: fixed;
  bottom: 0;
  background-color: #003300;
}


</style>
</head>


<body>

<div class="navbar">
<div class="navbar-left">
<img src="./Icons/CovisWeb.gif" height=40>
</div>

<a href="http://covis.cse.unt.edu/">Home</a>
<a href="http://covis.cse.unt.edu/projects.html">Projects</a>
<a href="http://covis.cse.unt.edu/publication.html">Publication</a>
<a href="http://covis.cse.unt.edu/members.html">Members</a>
<a href="http://covis.cse.unt.edu/Intranet">CoVIS Portal</a>
<a href="http://covis.cse.unt.edu/members.html#Contact">Contact</a>
</div>



<center>

<h3> Projects </h3>

<hr size=1 color=#004500>
<P>

<table width=90%>
<tr><td>
<!--span style='font-size:11pt'>   ;font-family:Helvetica'-->

<b>Sponsored by</b> &nbsp;&nbsp; <img src='./Icons/nasa.png' height=70 align='middle'> &nbsp;&nbsp; <img src='./Icons/usgs.png' height=50 align='middle'> &nbsp;&nbsp; <img src='./Icons/wpafb.gif' height=70 align='middle'> &nbsp;&nbsp; <img src='./Icons/nsf.jpg' height=70 align='middle'> &nbsp;&nbsp;
<img src='./Icons/nharp.jpg' height=70 align='middle'> &nbsp;&nbsp; <img src='./Icons/orau.jpg' height=70 align='middle'>
<p>

<font size=+1 color=#004500><b> Current</b></font><P>

<table>
<tr valign=top>
<td valign=top>
<b>Irrigation Status and Type Changes </b> <br>
Investigators: L. Lu and X. Yuan<br>
Sponsor: NASA and USGS <br>&nbsp;<br>
This project 
This project aims to enhance the collection and estimation of water-use data for crop 
irrigation -- the largest freshwater-use category in the US -- to better understand the 
availability and use of water resources that are needed to meet the Nation's water demands. 
Irrigated agriculture represents 20% of the total cultivated land in the US. It is also 
the largest freshwater user that accounted for 42% of total freshwater withdrawals and 
70% of the total fresh groundwater withdrawals nationwide. A detailed characterization 
of the irrigation status and system type for each crop field is a fundamental first step 
for more accurate water-use estimates. <P>

This project will 1) include classification of all four surface and one sprinkle irrigation 
type, and 2) scale up the application spatially and temporally to generate decadal-long 
irrigation type maps.<P>

<font size=-1>
<ul>
<li> Abolfazl Meyarian, Xiaohui Yuan, Lu Liang, Wencheng Wang, and Lichuan Gu, 
Gradient Convolutional Neural Network for Classification of Agricultural Fields with Contour Levee, 
International Journal of Remote Sensing, 43(1), pp. 75-94, 2022
<li> Lu Liang, Abolfazl Meyarian, Xiaohui Yuan, Benjamin R. K. Runkle, George Mihaila, 
Yuchu Qin, Jacob Daniels, Michele L. Reba, James R, Rigby, 
The First Fine-Resolution Mapping of Contour Levee Irrigation Using Deep Bi-Stream 
Convolutional Neural Networks, 
International Journal of Applied Earth Observation and Geoinformation, 105, 102631(1-10), December 2021
</ul>
</font>

</td>

<td align=middle><img src="./projects/classification.png" width=300></td>

</tr>


<tr valign=top><td valign=top>&nbsp;</td></tr>


<tr valign=top>
<td valign=top>
<b>Accurate Human Pose Estimation and Tracking</b> <br>
Investigators: X. Yuan, M. Elhoseny<br>
Sponsor: Physmodo, Inc. <br>&nbsp;<br>

Accurately tracking individual's free movements enables a better understanding of a person's activity level, inter-person
interaction, habits, etc. In this project, we aim at achieving a precise evaluation of human free movement in 3D space to quantify
a person's energy expenditure and emotional status.
<p>
<font size=-1>
<ul>
<li> Xiaohui Yuan and Amar Maharjan, Non-Rigid Point Set Registration: Recent Trends and Challenges, Artificial Intelligence Review, Oct., 2022 (accepted)
<li> Amar Maharjan and Xiaohui Yuan, Registration of Human Point Set using Automatic Key Point Detection and Region-aware Features, IEEE Winter Conference on Applications of Computer Vision (WACV), Waikoloa, HI, USA, Jan. 4-8, 2022
<li> A. Maharjan, X. Yuan, Q. Lu, Y. Fan, T. Chen, Non-Rigid Registration of Point Clouds using Landmarks and Stochastic Neighbor Embedding, Journal of Electronic Imaging, 30(3), pp. 031202(1-15), Jan. 2021
<li> A. Maharjan, X. Yuan, Point Set Registration of Large Deformation Using Auxiliary Landmarks, International Conference on Urban Intelligence and Applications, 86-98, Taiyuan, China, Aug. 14-16, 2020
<li> L. Kong, X. Yuan, A. M. Maharjan, A Hybrid Framework for Automatic Joint Detection of Human Poses in Depth Frames, Pattern Recognition, 77, 216-225, May 2018
<li> X. Yuan, D. Li, D. Mohapatra, M. Elhoseny, Automatic Removal of Complex Shadows from Indoor Videos using Transfer Learning and Dynamic Thresholding, Computers and Electrical Engineering, 70, 813-825, August 2018
<li> X. Yuan, L. Kong, D. Feng, Z. Wei, Automatic Feature Point Detection and Tracking of Human Action in Time-of-Flight Videos, IEEE/CAA Journal of Automatica Sinica, 4(4), 677-685, Oct. 2017
<li> Y. Zhou, J. Han, X. Yuan, Z. Wei, and R. Hong, Inverse Sparse Group Lasso Model for Robust Object Tracking, IEEE Transactions on Multimedia, 19(8), 1798-1810, Aug. 2017
<li> Y. Liu, Z. Xie, X. Yuan, J. Chen, W. Song, Multi-level Structured Hybrid Forest for Joint Head Detection and Pose Estimation, Neurocomputing, 266, 206-215, Aug. 2017
</ul>
</font>

</td>
<td align=middle><img src="./projects/Pose.png" width=300></td>
</tr>




</table>

&nbsp;<P>

<font size=+1 color=#004500><b>Completed</B></font> <P>
<B>Human Trusted Decision Fusion using Classifier Ensemble and Subgroup Feature Selection</B> (WP AFB, 2011.5 - 2011.8, 2012.5 - 2012.8, 2013.6-2013.8)
<br>
<B>Infusing Advanced Sensor Network Research into Cross-disciplinary Undergraduate Education</B> (NSF, 2009.4 - 2011.12)
<br>
<B>Computer-aided Diagnosis for Gastrointestinal Bleeding using Wireless Capsule Endoscopy</B>(Texas ARP, 2008.6 - 2010.6)
<br>
<B>A New Tool for Economic and Environmental Planning - Expanding the Boundaries of LiDAR</B> (NSF/SGER #0722106, 2007.7 - 2008.6) 
<br>
<B>US/China Digital Government Collaboration: A New Tool for Economic and Environmental Planning - Expanding the Boundaries of LiDAR</B> (NSF/SGER #0737861, 2007.9 - 2008.8) 
<br>
<B>Fusing LiDAR and Infrared to Model and Simulate Hydrological Events </B> (ORAU, 2008.7 - 2009.6)
<P>
&nbsp;<P>
<!--/span-->
</td></tr>
</table>
</center>

</body>
</html>
